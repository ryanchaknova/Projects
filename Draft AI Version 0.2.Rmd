---
title: "NBA DRAFT AI Version 0.2"
author: "Ryan Chaknova"
date: "2024-05-27"
output: html_document
---
```{r, echo=FALSE,warning=FALSE,message=FALSE}
Sys.setenv(RETICULATE_PYTHON = "C:/Users/Ryan/anaconda3")
library(reticulate)
py_config()
```
```{python,echo=FALSE,warning=FALSE,message=FALSE}
```


```{python,echo=FALSE,warning=FALSE,message=FALSE}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.model_selection import GridSearchCV
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
```

```{python,echo=FALSE,warning=FALSE,message=FALSE}

# Load datasets
college_draft_stats = pd.read_csv('2013_2018_COLLEGE_DRAFT_STATS_LAST.csv', index_col=False)
nba_ply_draft = pd.read_csv('2013_2023_NBA_PLY_DRAFT.csv', index_col=False)

# Drop unnamed columns
college_draft_stats.drop(college_draft_stats.columns[college_draft_stats.columns.str.contains('Unnamed', case=False)], axis=1, inplace=True)
nba_ply_draft.drop(nba_ply_draft.columns[nba_ply_draft.columns.str.contains('Unnamed', case=False)], axis=1, inplace=True)

# Columns to rename
columns_to_rename = ['G', 'MP', 'TRB', 'AST', 'PTS', 'WS', 'BPM']
renamed_columns = {col: col + '_NBA' for col in columns_to_rename}

# Rename columns in NBA data
nba_ply_draft.rename(columns=renamed_columns, inplace=True)

# Calculate WS_y in NBA dataset
nba_ply_draft["WS_y"] = nba_ply_draft["WS_NBA"] / nba_ply_draft["Yrs"]

# Merge datasets on Player name
merged_data = pd.merge(college_draft_stats, nba_ply_draft, on="Player", how="inner")

# Drop non-numeric columns
college_draft_stats_numeric = college_draft_stats.select_dtypes(include=[np.number])
nba_ply_draft_numeric = nba_ply_draft.select_dtypes(include=[np.number])
merged_data_numeric = merged_data.select_dtypes(include=[np.number])

# Select all features from the 2013-2018 college dataset
college_features = [col for col in college_draft_stats_numeric.columns if col != 'Player']

# Define features (X) and target variable (y)
X = merged_data[college_features].fillna(merged_data[college_features].mean())
y = merged_data["WS_y"].fillna(0)  # Set NaN values to 0 for the target variable

# Save player names
player_names = merged_data["Player"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test, player_names_train, player_names_test = train_test_split(X, y, player_names, test_size=0.2, random_state=42)

# Initialize the XGBoost Regressor
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 6, 9],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

# Initialize GridSearchCV with cross-validation
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')

# Fit GridSearchCV on the training data
grid_search.fit(X_train, y_train)

# Get the best parameters from the grid search
best_params = grid_search.best_params_

# Train the best model on the full training data
best_xgb_model = grid_search.best_estimator_

# Predict on the test data
y_pred_xgb = best_xgb_model.predict(X_test)

# Evaluate the tuned model
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)

# Reattach player names to the predictions
predictions_df = pd.DataFrame({
    "Player": player_names_test.reset_index(drop=True),
    "Actual_WS": y_test.reset_index(drop=True),
    "Predicted_WS": y_pred_xgb
})



print("Best Parameters:", best_params)
print("Mean Squared Error:", mse_xgb)
print("R2 Score:", r2_xgb)

# Display the predictions with player names
predictions_df

# Scatter plot: Actual vs. Predicted with Player Names
plt.figure(figsize=(14, 8))
sns.scatterplot(x="Actual_WS", y="Predicted_WS", data=predictions_df)

# Add annotations for player names
for i in range(predictions_df.shape[0]):
    plt.text(x=predictions_df["Actual_WS"].iloc[i],
             y=predictions_df["Predicted_WS"].iloc[i],
             s=predictions_df["Player"].iloc[i],
             fontdict=dict(color='black', size=8),
             bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))

plt.plot([predictions_df["Actual_WS"].min(), predictions_df["Actual_WS"].max()],
         [predictions_df["Actual_WS"].min(), predictions_df["Actual_WS"].max()],
         color='red', lw=2, linestyle='--')
plt.title("Actual vs. Predicted Win Shares Per Year with Player Names")
plt.xlabel("Actual Win Shares Per Year")
plt.ylabel("Predicted Win Shares Per Year")
plt.show()

# Residual plot: Errors
predictions_df["Residuals"] = predictions_df["Actual_WS"] - predictions_df["Predicted_WS"]
plt.figure(figsize=(10, 6))
sns.scatterplot(x="Predicted_WS", y="Residuals", data=predictions_df)
plt.axhline(y=0, color='red', lw=2, linestyle='--')
plt.title("Residuals Plot")
plt.xlabel("Predicted Win Shares Per Year")
plt.ylabel("Residuals")
plt.show()

# Feature Importance
plt.figure(figsize=(12, 8))
xgb.plot_importance(best_xgb_model, max_num_features=10, importance_type='gain')
plt.title("Feature Importance")
plt.show()
```

this certainly has much room for improvement, as expected
